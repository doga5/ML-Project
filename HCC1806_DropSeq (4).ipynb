{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10b6c796",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39ead7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8764caf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = ''\n",
    "\n",
    "with open(file_path, 'r') as f:\n",
    "    header = f.readline().replace('\"', '').strip().split()\n",
    "\n",
    "header = ['Gene'] + header\n",
    "\n",
    "df = pd.read_csv(file_path,\n",
    "                 sep='\\s+',       \n",
    "                 quotechar='\"',    \n",
    "                 skiprows=1,       \n",
    "                 header=None)     \n",
    "\n",
    "df.columns = header\n",
    "df.set_index('Gene', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "944a9c12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAAAAACCCGGC_Normoxia</th>\n",
       "      <th>AAAACCGGATGC_Normoxia</th>\n",
       "      <th>AAAACGAGCTAG_Normoxia</th>\n",
       "      <th>AAAACTTCCCCG_Normoxia</th>\n",
       "      <th>AAAAGCCTACCC_Normoxia</th>\n",
       "      <th>AAACACAAATCT_Normoxia</th>\n",
       "      <th>AAACCAAGCCCA_Normoxia</th>\n",
       "      <th>AAACCATGCACT_Normoxia</th>\n",
       "      <th>AAACCTCCGGCT_Normoxia</th>\n",
       "      <th>AAACGCCGGTCC_Normoxia</th>\n",
       "      <th>...</th>\n",
       "      <th>TTTTCTGATGGT_Hypoxia</th>\n",
       "      <th>TTTTGATTCAGA_Hypoxia</th>\n",
       "      <th>TTTTGCAACTGA_Hypoxia</th>\n",
       "      <th>TTTTGCCGGGCC_Hypoxia</th>\n",
       "      <th>TTTTGTTAGCCT_Hypoxia</th>\n",
       "      <th>TTTTTACCAATC_Hypoxia</th>\n",
       "      <th>TTTTTCCGTGCA_Hypoxia</th>\n",
       "      <th>TTTTTGCCTGGG_Hypoxia</th>\n",
       "      <th>TTTTTGTAACAG_Hypoxia</th>\n",
       "      <th>TTTTTTTGAATC_Hypoxia</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gene</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>H1-5</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MALAT1</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MT-RNR2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARVCF</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BCYRN1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 14682 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         AAAAAACCCGGC_Normoxia  AAAACCGGATGC_Normoxia  AAAACGAGCTAG_Normoxia  \\\n",
       "Gene                                                                           \n",
       "H1-5                         2                      2                      5   \n",
       "MALAT1                       3                      3                      2   \n",
       "MT-RNR2                      0                      0                      0   \n",
       "ARVCF                        0                      0                      0   \n",
       "BCYRN1                       0                      1                      1   \n",
       "\n",
       "         AAAACTTCCCCG_Normoxia  AAAAGCCTACCC_Normoxia  AAACACAAATCT_Normoxia  \\\n",
       "Gene                                                                           \n",
       "H1-5                         1                      0                      0   \n",
       "MALAT1                       3                     12                      3   \n",
       "MT-RNR2                      0                      0                      0   \n",
       "ARVCF                        0                      0                      0   \n",
       "BCYRN1                       0                      0                      1   \n",
       "\n",
       "         AAACCAAGCCCA_Normoxia  AAACCATGCACT_Normoxia  AAACCTCCGGCT_Normoxia  \\\n",
       "Gene                                                                           \n",
       "H1-5                         0                      0                      1   \n",
       "MALAT1                       1                      2                      0   \n",
       "MT-RNR2                      0                      0                      0   \n",
       "ARVCF                        0                      0                      0   \n",
       "BCYRN1                       1                      2                      0   \n",
       "\n",
       "         AAACGCCGGTCC_Normoxia  ...  TTTTCTGATGGT_Hypoxia  \\\n",
       "Gene                            ...                         \n",
       "H1-5                         0  ...                     0   \n",
       "MALAT1                       0  ...                     3   \n",
       "MT-RNR2                      1  ...                     1   \n",
       "ARVCF                        0  ...                     0   \n",
       "BCYRN1                       3  ...                     1   \n",
       "\n",
       "         TTTTGATTCAGA_Hypoxia  TTTTGCAACTGA_Hypoxia  TTTTGCCGGGCC_Hypoxia  \\\n",
       "Gene                                                                        \n",
       "H1-5                        1                     0                     2   \n",
       "MALAT1                      1                     1                     1   \n",
       "MT-RNR2                     2                     2                     2   \n",
       "ARVCF                       0                     0                     0   \n",
       "BCYRN1                      1                     0                     1   \n",
       "\n",
       "         TTTTGTTAGCCT_Hypoxia  TTTTTACCAATC_Hypoxia  TTTTTCCGTGCA_Hypoxia  \\\n",
       "Gene                                                                        \n",
       "H1-5                        1                     0                     0   \n",
       "MALAT1                      4                     0                     4   \n",
       "MT-RNR2                     0                     0                     1   \n",
       "ARVCF                       0                     0                     0   \n",
       "BCYRN1                      1                     0                     0   \n",
       "\n",
       "         TTTTTGCCTGGG_Hypoxia  TTTTTGTAACAG_Hypoxia  TTTTTTTGAATC_Hypoxia  \n",
       "Gene                                                                       \n",
       "H1-5                        0                     3                     1  \n",
       "MALAT1                      1                     3                     6  \n",
       "MT-RNR2                     0                     1                     0  \n",
       "ARVCF                       0                     0                     0  \n",
       "BCYRN1                      1                     0                     0  \n",
       "\n",
       "[5 rows x 14682 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8bf0be33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 14682)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714c3475",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)\n",
    "print(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13178815",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAAAAACCCGGC_Normoxia</th>\n",
       "      <th>AAAACCGGATGC_Normoxia</th>\n",
       "      <th>AAAACGAGCTAG_Normoxia</th>\n",
       "      <th>AAAACTTCCCCG_Normoxia</th>\n",
       "      <th>AAAAGCCTACCC_Normoxia</th>\n",
       "      <th>AAACACAAATCT_Normoxia</th>\n",
       "      <th>AAACCAAGCCCA_Normoxia</th>\n",
       "      <th>AAACCATGCACT_Normoxia</th>\n",
       "      <th>AAACCTCCGGCT_Normoxia</th>\n",
       "      <th>AAACGCCGGTCC_Normoxia</th>\n",
       "      <th>...</th>\n",
       "      <th>TTTTCTGATGGT_Hypoxia</th>\n",
       "      <th>TTTTGATTCAGA_Hypoxia</th>\n",
       "      <th>TTTTGCAACTGA_Hypoxia</th>\n",
       "      <th>TTTTGCCGGGCC_Hypoxia</th>\n",
       "      <th>TTTTGTTAGCCT_Hypoxia</th>\n",
       "      <th>TTTTTACCAATC_Hypoxia</th>\n",
       "      <th>TTTTTCCGTGCA_Hypoxia</th>\n",
       "      <th>TTTTTGCCTGGG_Hypoxia</th>\n",
       "      <th>TTTTTGTAACAG_Hypoxia</th>\n",
       "      <th>TTTTTTTGAATC_Hypoxia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3000.00000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.00000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.02900</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.024333</td>\n",
       "      <td>0.021667</td>\n",
       "      <td>0.029667</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.036000</td>\n",
       "      <td>0.02600</td>\n",
       "      <td>0.034000</td>\n",
       "      <td>0.029333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043000</td>\n",
       "      <td>0.049667</td>\n",
       "      <td>0.037000</td>\n",
       "      <td>0.047667</td>\n",
       "      <td>0.057000</td>\n",
       "      <td>0.023333</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.043333</td>\n",
       "      <td>0.040000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.23276</td>\n",
       "      <td>0.309778</td>\n",
       "      <td>0.231860</td>\n",
       "      <td>0.189409</td>\n",
       "      <td>0.323761</td>\n",
       "      <td>0.170126</td>\n",
       "      <td>0.250449</td>\n",
       "      <td>0.23525</td>\n",
       "      <td>0.231362</td>\n",
       "      <td>0.218683</td>\n",
       "      <td>...</td>\n",
       "      <td>0.271739</td>\n",
       "      <td>0.319219</td>\n",
       "      <td>0.279864</td>\n",
       "      <td>0.259648</td>\n",
       "      <td>0.304053</td>\n",
       "      <td>0.214797</td>\n",
       "      <td>0.236536</td>\n",
       "      <td>0.285116</td>\n",
       "      <td>0.267356</td>\n",
       "      <td>0.282418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.00000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 14682 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       AAAAAACCCGGC_Normoxia  AAAACCGGATGC_Normoxia  AAAACGAGCTAG_Normoxia  \\\n",
       "count             3000.00000            3000.000000            3000.000000   \n",
       "mean                 0.02900               0.041667               0.024333   \n",
       "std                  0.23276               0.309778               0.231860   \n",
       "min                  0.00000               0.000000               0.000000   \n",
       "25%                  0.00000               0.000000               0.000000   \n",
       "50%                  0.00000               0.000000               0.000000   \n",
       "75%                  0.00000               0.000000               0.000000   \n",
       "max                  5.00000               9.000000               7.000000   \n",
       "\n",
       "       AAAACTTCCCCG_Normoxia  AAAAGCCTACCC_Normoxia  AAACACAAATCT_Normoxia  \\\n",
       "count            3000.000000            3000.000000            3000.000000   \n",
       "mean                0.021667               0.029667               0.020000   \n",
       "std                 0.189409               0.323761               0.170126   \n",
       "min                 0.000000               0.000000               0.000000   \n",
       "25%                 0.000000               0.000000               0.000000   \n",
       "50%                 0.000000               0.000000               0.000000   \n",
       "75%                 0.000000               0.000000               0.000000   \n",
       "max                 4.000000              12.000000               3.000000   \n",
       "\n",
       "       AAACCAAGCCCA_Normoxia  AAACCATGCACT_Normoxia  AAACCTCCGGCT_Normoxia  \\\n",
       "count            3000.000000             3000.00000            3000.000000   \n",
       "mean                0.036000                0.02600               0.034000   \n",
       "std                 0.250449                0.23525               0.231362   \n",
       "min                 0.000000                0.00000               0.000000   \n",
       "25%                 0.000000                0.00000               0.000000   \n",
       "50%                 0.000000                0.00000               0.000000   \n",
       "75%                 0.000000                0.00000               0.000000   \n",
       "max                 4.000000                6.00000               4.000000   \n",
       "\n",
       "       AAACGCCGGTCC_Normoxia  ...  TTTTCTGATGGT_Hypoxia  TTTTGATTCAGA_Hypoxia  \\\n",
       "count            3000.000000  ...           3000.000000           3000.000000   \n",
       "mean                0.029333  ...              0.043000              0.049667   \n",
       "std                 0.218683  ...              0.271739              0.319219   \n",
       "min                 0.000000  ...              0.000000              0.000000   \n",
       "25%                 0.000000  ...              0.000000              0.000000   \n",
       "50%                 0.000000  ...              0.000000              0.000000   \n",
       "75%                 0.000000  ...              0.000000              0.000000   \n",
       "max                 4.000000  ...              4.000000              7.000000   \n",
       "\n",
       "       TTTTGCAACTGA_Hypoxia  TTTTGCCGGGCC_Hypoxia  TTTTGTTAGCCT_Hypoxia  \\\n",
       "count           3000.000000           3000.000000           3000.000000   \n",
       "mean               0.037000              0.047667              0.057000   \n",
       "std                0.279864              0.259648              0.304053   \n",
       "min                0.000000              0.000000              0.000000   \n",
       "25%                0.000000              0.000000              0.000000   \n",
       "50%                0.000000              0.000000              0.000000   \n",
       "75%                0.000000              0.000000              0.000000   \n",
       "max                7.000000              4.000000              5.000000   \n",
       "\n",
       "       TTTTTACCAATC_Hypoxia  TTTTTCCGTGCA_Hypoxia  TTTTTGCCTGGG_Hypoxia  \\\n",
       "count           3000.000000           3000.000000           3000.000000   \n",
       "mean               0.023333              0.041667              0.041667   \n",
       "std                0.214797              0.236536              0.285116   \n",
       "min                0.000000              0.000000              0.000000   \n",
       "25%                0.000000              0.000000              0.000000   \n",
       "50%                0.000000              0.000000              0.000000   \n",
       "75%                0.000000              0.000000              0.000000   \n",
       "max                4.000000              4.000000              5.000000   \n",
       "\n",
       "       TTTTTGTAACAG_Hypoxia  TTTTTTTGAATC_Hypoxia  \n",
       "count           3000.000000           3000.000000  \n",
       "mean               0.043333              0.040000  \n",
       "std                0.267356              0.282418  \n",
       "min                0.000000              0.000000  \n",
       "25%                0.000000              0.000000  \n",
       "50%                0.000000              0.000000  \n",
       "75%                0.000000              0.000000  \n",
       "max                5.000000              6.000000  \n",
       "\n",
       "[8 rows x 14682 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a61f2bf",
   "metadata": {},
   "source": [
    "# Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ed76f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnames = list(df.columns)\n",
    "cnames[100]\n",
    "sns.boxplot(x=df[cnames[100]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e5cb61",
   "metadata": {},
   "source": [
    "This boxplot shows the distribution of expression levels for the gene AACGCCCCGGG_Normoxia across the samples in the dataset. The data points appear to be discrete and spread out across a range of integer values from 0 to 5, with no clear interquartile box visible — this suggests either a very small number of data points or very sparse expression levels. Outliers are shown as individual points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815fd416",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.violinplot(x=df[cnames[100]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882d26d4",
   "metadata": {},
   "source": [
    "This violin plot shows the distribution of expression levels for the gene AACGCCCCGGG_Normoxia across the samples in the dataset. The distribution is heavily skewed toward very low expression levels (near zero), with the majority of values clustered at or below 1. A small number of samples exhibit higher expression levels (up to 5), but these are rare. This pattern suggests that the gene is mostly inactive or weakly expressed across the dataset, with occasional higher expression in a few samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a741b185",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_stats = pd.DataFrame(index=df.index)  \n",
    "gene_stats['mean'] = df.mean(axis=1)\n",
    "gene_stats['std'] = df.std(axis=1)\n",
    "gene_stats['min'] = df.min(axis=1)\n",
    "gene_stats['max'] = df.max(axis=1)\n",
    "gene_stats['zero_fraction'] = (df == 0).sum(axis=1) / df.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b999af5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_stats['mean'].hist(bins=50)\n",
    "plt.title(\"Histogram of Mean Gene Expression\")\n",
    "plt.xlabel(\"Mean Expression\")\n",
    "plt.ylabel(\"Number of Genes\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af797e6",
   "metadata": {},
   "source": [
    "This histogram shows the distribution of mean gene expression levels across all genes in our dataset. The majority of genes have a very low mean expression, with most clustered near zero. Only a small number of genes show higher mean expression values (> 0.5). This is a typical pattern in gene expression data, where most genes are inactive or lowly expressed, while a few genes are highly expressed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1234bc19",
   "metadata": {},
   "source": [
    "Since our data is big, we will look at the most expressed genes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecf18d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_variable_genes = gene_stats['std'].sort_values(ascending=False).head(50).index\n",
    "df_filtered = df.loc[top_variable_genes]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7f6715",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered.T.boxplot(showfliers=False, figsize=(14, 6))\n",
    "plt.title(\"Expression Distribution per Sample (Top 50 Genes)\")\n",
    "plt.ylabel(\"Counts\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e19c5c",
   "metadata": {},
   "source": [
    "This boxplot shows the distribution of expression counts for the top 50 most variable genes across all samples in the dataset. Most genes exhibit low expression counts, with medians typically around 1–2 counts. Some genes, such as H4C3 and MALAT1, show higher expression levels with greater variability across samples. This visualization highlights the variation in expression patterns among the most informative genes in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0859f24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "top_50 = df_filtered.var(axis=1).sort_values(ascending=False).head(50).index\n",
    "top_50_data = df_filtered.loc[top_50]\n",
    "\n",
    "zscore_data = (top_50_data - top_50_data.mean(axis=1).values[:, None]) / top_50_data.std(axis=1).values[:, None]\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(zscore_data, cmap='viridis', xticklabels=False)\n",
    "plt.title(\"Heatmap: Top 50 Most Variable Genes\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34464f07",
   "metadata": {},
   "source": [
    "This heatmap shows the expression levels of the top 50 most variable genes across all samples in the dataset. Each row represents a gene, and each column represents a sample. The color intensity reflects the expression level, with darker colors indicating lower expression and brighter colors indicating higher expression. The variation in color patterns highlights the differences in expression of these genes across samples, helping to identify potential biological patterns or sample-specific effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99de232f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small = df.iloc[:, :50]\n",
    "np.shape(df_small)\n",
    "plt.figure(figsize=(16,4))\n",
    "plot=sns.violinplot(data=df_small,palette=\"Set3\",cut=0)\n",
    "plt.setp(plot.get_xticklabels(), rotation=90)\n",
    "plt.title('Violin plot of the first 50 genes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730535c9",
   "metadata": {},
   "source": [
    "In this violin plot, we can see the distribution of expression levels for the first 50 genes in the dataset. Each violin represents one gene, with the width indicating the density of samples at different expression levels. The majority of genes display highly skewed distributions, with many samples having low expression levels and a few showing higher expression values. The variation in violin shapes suggests differing expression patterns and variability among these genes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476e4852",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_stats['variance'] = df.var(axis=1)\n",
    "\n",
    "plt.scatter(gene_stats['mean'], gene_stats['variance'], alpha=0.5, s=10)\n",
    "plt.title(\"Mean vs Variance of Gene Expression\")\n",
    "plt.xlabel(\"Mean Expression\")\n",
    "plt.ylabel(\"Variance\")\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2853b0",
   "metadata": {},
   "source": [
    "This scatter plot shows the relationship between the mean and variance of gene expression levels across all genes in the dataset. Both axes are plotted on a logarithmic scale. The plot reveals a strong positive correlation: as mean expression increases, variance also increases. This pattern is typical in gene expression data, as genes with higher average expression levels tend to show greater variability across samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3827b314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 97.64%\n"
     ]
    }
   ],
   "source": [
    "total_values = df.size\n",
    "\n",
    "zero_values = (df == 0).sum().sum()\n",
    "\n",
    "sparsity = zero_values / total_values\n",
    "print(f\"Sparsity: {sparsity:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3098720",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import kurtosis, skew\n",
    "colN = np.shape(df)[1]\n",
    "colN\n",
    "df_skew_cells = []\n",
    "for i in range(colN) :\n",
    "     v_df = df[cnames[i]]\n",
    "     df_skew_cells += [skew(v_df)]\n",
    "df_skew_cells\n",
    "sns.histplot(df_skew_cells,bins=100)\n",
    "plt.xlabel('Skewness of single cells expression profiles - original df')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ff80fe",
   "metadata": {},
   "source": [
    "This histogram shows the distribution of skewness values for single-cell gene expression profiles in the original dataset. Most cells exhibit positive skewness, meaning that their expression profiles are dominated by a large number of low-expression genes and a few high-expression ones. The peak around a skewness value of ~10 suggests that this pattern is consistent across most cells. The long right tail indicates that some cells have even more extreme skewness, with a stronger imbalance toward low expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5406bee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kurt_cells = []\n",
    "for i in range(colN) :\n",
    "     v_df = df[cnames[i]]\n",
    "     df_kurt_cells += [kurtosis(v_df)]\n",
    "df_kurt_cells\n",
    "sns.histplot(df_kurt_cells,bins=100)\n",
    "plt.xlabel('Kurtosis of single cells expression profiles - original df')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff42e000",
   "metadata": {},
   "source": [
    "The histogram above shows the distribution of kurtosis values for single-cell gene expression profiles in the original dataset. Most cells exhibit high kurtosis, indicating that their expression profiles are dominated by a few extreme values (very high expression in a few genes) and many low values. The peak near lower kurtosis values suggests that most cells have moderately heavy-tailed distributions, while the long right tail indicates that some cells have very extreme kurtosis, reflecting strong outliers or highly peaked distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da92012e",
   "metadata": {},
   "source": [
    "In the code below, we choose part of the samples so that run time is not too long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8c64be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small = df.iloc[:, 10:30]  \n",
    "sns.displot(data=df_small,palette=\"Set3\",kind=\"kde\", bw_adjust=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d596b7dc",
   "metadata": {},
   "source": [
    "This KDE plot shows the density distribution of expression levels for a subset of 20 genes (from the first 10 to 30 in the dataset) under Normoxia conditions. The plot highlights that the majority of expression values for these genes are concentrated near zero, with a sharp peak and a long tail extending toward higher values. This indicates that most genes are expressed at low levels, while a few cells or samples exhibit higher expression, consistent with the sparse nature of single-cell gene expression data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847e82dc",
   "metadata": {},
   "source": [
    "## Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c38a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_corr = df_small.corr() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1afb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cell_corr, cmap=\"coolwarm\", center=0)\n",
    "plt.title(\"Cell-Cell Correlation Matrix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f55c571",
   "metadata": {},
   "source": [
    "This heatmap shows the cell-cell correlation matrix for a subset of single cells under Normoxia conditions. Each cell is compared with every other cell, and the color intensity indicates the strength of correlation (from 0 to 1). The diagonal shows perfect self-correlation (correlation = 1). Off-diagonal values vary, suggesting that while some cells have moderately similar expression profiles, many show low-to-moderate correlation, reflecting biological variability and technical noise common in single-cell data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e2b742",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_corr = cell_corr.mean()\n",
    "low_corr_cells = mean_corr[mean_corr < 0.5]\n",
    "print(\"Low correlation cells:\", low_corr_cells.index.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a580ecd",
   "metadata": {},
   "source": [
    "In this code, we calculate the mean correlation of each cell with all other cells and identifie those with a mean correlation below 0.5. The output lists several Normoxia cells with low correlation, indicating that these cells have expression profiles that differ substantially from the rest of the dataset. Such low-correlation cells may represent biological outliers, technical artifacts, or low-quality cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa410e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_genes = df.var(axis=1).sort_values(ascending=False).head(50).index\n",
    "gene_corr = df.loc[top_genes].T.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7795939",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(gene_corr, cmap=\"coolwarm\", center=0)\n",
    "plt.title(\"Gene–Gene Correlation (Top 50 Most Variable Genes)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab31b74",
   "metadata": {},
   "source": [
    "This heatmap shows the gene-gene correlation matrix for the top 50 most variable genes in the dataset. Each gene is compared with every other gene, and the color intensity indicates the strength of correlation, ranging from -0.2 (blue, negative correlation) to +1.0 (red, strong positive correlation). The diagonal shows perfect self-correlation (correlation = 1). Most off-diagonal values are low to moderate, suggesting that while some genes are co-regulated, many vary independently, which is typical in complex biological systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72591eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(cell_corr)\n",
    "type(cell_corr)\n",
    "cell_corr.head(3)\n",
    "c_small=cell_corr.iloc[:,:3]\n",
    "sns.histplot(c_small,bins=100)\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('Correlation between cells expression profiles')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf60cdaa",
   "metadata": {},
   "source": [
    "This histogram shows the distribution of correlation values between the expression profiles of three selected cells under Normoxia conditions. Each bar represents how frequently a given correlation value occurs between one cell and all other cells. The distributions vary across cells, with most correlation values falling between 0.2 and 0.6, and a few values close to 1.0 (self-correlation). This suggests that these cells generally have moderate similarity with others, but the presence of low correlations highlights variability among cell expression profiles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7879d3bd",
   "metadata": {},
   "source": [
    "# Filter The Cells "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15837f94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 14682)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3feafcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"Initial shape:\", df.shape)\n",
    "zero_fraction = (df == 0).sum(axis=0) / df.shape[0]\n",
    "\n",
    "total_expression = df.sum(axis=0)\n",
    "\n",
    "plt.hist(zero_fraction, bins=50)\n",
    "plt.title(\"Fraction of Zeros per Sample\")\n",
    "plt.xlabel(\"Fraction\")\n",
    "plt.ylabel(\"Number of Samples\")\n",
    "plt.show()\n",
    "\n",
    "plt.hist(total_expression, bins=50)\n",
    "plt.title(\"Total Expression per Sample\")\n",
    "plt.xlabel(\"Total Expression\")\n",
    "plt.ylabel(\"Number of Samples\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d4f96f",
   "metadata": {},
   "source": [
    "We will try to filter our data by eliminating the samples that have more than 100 zero entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b6dbbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "nonzero_per_sample = (df != 0).sum(axis=0)  \n",
    "threshold = 100 \n",
    "filtered_df = df.loc[:, nonzero_per_sample > threshold]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34e57035",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 2037)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2568b3c9",
   "metadata": {},
   "source": [
    "We check if, after filtering, our data is balanced in terms of hypoxia and normoxia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1335d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "sample_names_train =filtered_df.T.index\n",
    "\n",
    "y_train = np.array([1 if \"Hypoxia\" in name else 0 for name in sample_names_train])\n",
    "\n",
    "print(pd.Series(y_train, index=sample_names_train).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc686c1",
   "metadata": {},
   "source": [
    "It seems that our zero samples are mostly normoxia. This inbalanced labes can hurt the reliabilty of our machine learning models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc24c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_names_train =df.T.index\n",
    "\n",
    "labels_array=np.array([1 if \"Hypoxia\" in name else 0 for name in sample_names_train])\n",
    "print(pd.Series(labels_array, index=sample_names_train).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5245ac09",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_series = pd.Series(labels_array, index=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c97d05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hypoxia_cells = labels_series[labels_series == 1].index\n",
    "normoxia_cells = labels_series[labels_series == 0].index\n",
    "\n",
    "expr_hypoxia = df[hypoxia_cells]\n",
    "expr_normoxia = df[normoxia_cells]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f294c42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_hypoxia = expr_hypoxia.loc[:, (expr_hypoxia != 0).sum(axis=0) >= 70]\n",
    "filtered_normoxia = expr_normoxia.loc[:, (expr_normoxia != 0).sum(axis=0) >= 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fb448ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = pd.concat([filtered_hypoxia, filtered_normoxia], axis=1)\n",
    "filtered_labels = labels_series[filtered_df.columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16df6612",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(filtered_labels.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecee7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "763e6775",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = filtered_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9180a4ec",
   "metadata": {},
   "source": [
    "# Unsupervised Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd765e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee080af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df.T\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd916703",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab52079",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a8cd4e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "X_scaled = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed0d598",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "pca = PCA().fit(X_scaled)\n",
    "\n",
    "cumvar = np.cumsum(pca.explained_variance_ratio_)\n",
    "\n",
    "plt.plot(np.arange(1, len(cumvar)+1), cumvar, marker='o')\n",
    "plt.axhline(0.90, color='gray', linestyle='--', label='90% variance')\n",
    "plt.xlabel(\"Number of PCs\")\n",
    "plt.ylabel(\"Cumulative Explained Variance\")\n",
    "plt.title(\"Elbow Plot: Choosing Number of PCs\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839f5787",
   "metadata": {},
   "source": [
    "This elbow plot shows the cumulative explained variance as a function of the number of principal components derived from PCA on the scaled dataset. The curve rises steeply at first and then levels off, indicating diminishing returns in explained variance as more principal components are added. The dashed line marks the point where 90% of the total variance is captured. This plot helps determine an appropriate number of principal components to retain for dimensionality reduction—typically where the “elbow” of the curve occurs, balancing information retention and model simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "374573f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2102\n",
      "(8838, 2102)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca90 = PCA(n_components = 0.90) \n",
    "X_pca90 = pca90.fit_transform(X_scaled)\n",
    "print(pca90.n_components_)\n",
    "print(X_pca90.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b532e202",
   "metadata": {},
   "source": [
    "This number of p.c. indicatets that our data is highly complex and spread across many dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a491576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.10173375 -0.09841931  0.02536911 ... -0.00643682  0.01375507\n",
      "  -0.00079472]\n",
      " [-0.00900859 -0.00327057  0.05869342 ...  0.00451379 -0.000786\n",
      "   0.00063733]\n",
      " [-0.08377144  0.07853484 -0.04348605 ... -0.00532137  0.0143405\n",
      "   0.00258016]\n",
      " ...\n",
      " [ 0.01320995  0.01796377  0.01298472 ... -0.00419772 -0.0172389\n",
      "   0.00304296]\n",
      " [-0.05302489 -0.00043759  0.0083675  ... -0.02656647  0.00347543\n",
      "  -0.01886014]\n",
      " [-0.02865608 -0.01124854 -0.00523666 ... -0.02608494  0.02881915\n",
      "   0.01023348]]\n"
     ]
    }
   ],
   "source": [
    "print(pca90.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4134494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00561316 0.00249455 0.00232915 ... 0.00027177 0.00027144 0.00027061]\n"
     ]
    }
   ],
   "source": [
    "print(pca90.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4b98f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999628855646314\n"
     ]
    }
   ],
   "source": [
    "print(1 - pca90.explained_variance_ratio_.sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcffdbe",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "13da9774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k =  2 → silhouette = 0.124\n",
      "k =  3 → silhouette = 0.074\n",
      "k =  4 → silhouette = 0.074\n",
      "k =  5 → silhouette = -0.107\n",
      "k =  6 → silhouette = -0.107\n",
      "k =  7 → silhouette = -0.105\n",
      "k =  8 → silhouette = -0.107\n",
      "k =  9 → silhouette = -0.106\n",
      "k = 10 → silhouette = -0.106\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "X_pca = X_pca90  \n",
    "\n",
    "ks = np.arange(2, 11)           \n",
    "sil_scores = []                \n",
    "\n",
    "for k in ks:\n",
    "    km = KMeans(n_clusters=k, random_state=42).fit(X_pca)\n",
    "    labels = km.labels_\n",
    "    sil = silhouette_score(X_pca, labels)\n",
    "    sil_scores.append(sil)\n",
    "    print(f\"k = {k:2d} → silhouette = {sil:.3f}\")\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(ks, sil_scores, marker='o')\n",
    "plt.xticks(ks)\n",
    "plt.xlabel(\"Number of clusters (k)\")\n",
    "plt.ylabel(\"Silhouette score\")\n",
    "plt.title(\"Silhouette analysis for K-Means\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269a6d26",
   "metadata": {},
   "source": [
    "This plot shows the silhouette scores for K-Means clustering using different numbers of clusters (k) on the PCA-transformed dataset. The silhouette score measures how well-separated the clusters are, with higher values indicating better-defined clusters. The score peaks at k = 2 , suggesting that two clusters provide the best separation in the data. For larger values of k, the silhouette scores decrease or remain low, indicating that additional clusters do not improve the clustering quality and may lead to overfitting or poorly separated groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c9ef78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "n_clusters = 2  \n",
    "\n",
    "\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=0)\n",
    "cluster_labels = kmeans.fit_predict(X_pca90)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "scatter = plt.scatter(\n",
    "    X_pca90[:,0], X_pca90[:,1],\n",
    "    c=cluster_labels, cmap='tab10', s=10, alpha=0.8\n",
    ")\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.title(f\"KMeans (k={n_clusters}) on PCA space\")\n",
    "plt.legend(*scatter.legend_elements(), title=\"Cluster\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb70ce7",
   "metadata": {},
   "source": [
    "In this scatter plot, we see the results of K-Means clustering with k = 2 applied to the dataset projected onto the first two principal components (PC1 and PC2). Each point represents a single cell, colored according to its assigned cluster. The plot shows a clear separation between the two clusters along the PC1 axis, suggesting that this principal component captures much of the variation driving the clustering. The visualization helps assess how well the clusters are distinguished in the reduced-dimensional space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7a44b3c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 1, 1, 1], dtype=int32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = cluster_labels\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27063a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['Cluster'] = labels\n",
    "X_train['Cluster'].value_counts()\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='Cluster', data=X_train, palette='Set2')\n",
    "plt.title(\"Cluster Distribution\")\n",
    "plt.xlabel(\"Cluster\")\n",
    "plt.ylabel(\"Number of Samples\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0a42db",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_names = X_train[X_train['Cluster'] == 0].index.tolist()\n",
    "cell_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676d974a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_names2 = X_train[X_train['Cluster'] == 1].index.tolist()\n",
    "cell_names2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140a7465",
   "metadata": {},
   "source": [
    "# Supervised Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "76be2a03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8838, 3000)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = df.T \n",
    "X_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bc06f8af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    4870\n",
      "1    3968\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "sample_names_train = X_train.index\n",
    "\n",
    "y_train = np.array([1 if \"Hypoxia\" in name else 0 for name in sample_names_train])\n",
    "\n",
    "print(pd.Series(y_train, index=sample_names_train).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9ef63f",
   "metadata": {},
   "source": [
    "## Finding the best model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c1f56c",
   "metadata": {},
   "source": [
    "We now prepare a set of classification models to compare. We import six different models: Logistic Regression, Random Forest, SVM, Naive Bayes, K-Nearest Neighbors, and Decision Tree. We will evaluate their performance on our data based on cross validation accuracy and accuracy on training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "49603e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, solver='liblinear'),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100),\n",
    "    \"SVM\": SVC(kernel='linear'),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1252ce8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: CV accuracy = 0.8966\n",
      "Logistic Regression: Training accuracy = 0.8994\n",
      "Random Forest: CV accuracy = 0.8865\n",
      "Random Forest: Training accuracy = 0.9282\n",
      "SVM: CV accuracy = 0.8967\n",
      "SVM: Training accuracy = 0.8992\n",
      "Naive Bayes: CV accuracy = 0.8589\n",
      "Naive Bayes: Training accuracy = 0.8672\n",
      "KNN: CV accuracy = 0.8491\n",
      "KNN: Training accuracy = 0.8345\n",
      "Decision Tree: CV accuracy = 0.8685\n",
      "Decision Tree: Training accuracy = 0.9282\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    pipe = Pipeline([\n",
    "        (\"scale\", StandardScaler()),\n",
    "        (\"var_thresh\", VarianceThreshold(threshold=0.0)),\n",
    "        (\"select\", SelectKBest(score_func=f_classif)), \n",
    "        (\"pca\", PCA(random_state=42)), \n",
    "        (\"clf\", model)\n",
    "    ])\n",
    "    scores = cross_val_score(pipe, X_train, y_train, cv=5)\n",
    "    results[name] = scores.mean()\n",
    "    print(f\"{name}: CV accuracy = {scores.mean():.4f}\")\n",
    "    print(f\"{name}: Training accuracy = {pipe.fit(X_train, y_train).score(X_train, y_train):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a1bf888c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM                   CV Accuracy: 0.8967\n",
      "Logistic Regression   CV Accuracy: 0.8966\n",
      "Random Forest         CV Accuracy: 0.8865\n",
      "Decision Tree         CV Accuracy: 0.8685\n",
      "Naive Bayes           CV Accuracy: 0.8589\n",
      "KNN                   CV Accuracy: 0.8491\n"
     ]
    }
   ],
   "source": [
    "sorted_results = sorted(results.items(), key=lambda x: x[1], reverse=True)\n",
    "for name, score in sorted_results:\n",
    "    print(f\"{name:<20}  CV Accuracy: {score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de13d417",
   "metadata": {},
   "source": [
    "SVM and Logistic Regression models give better accuracy scores than others, however Perfect training accuracy and ignificant gap between training and CV accuracy implies overfitting. Now we will perform randomized search to tune best-performing models in order to solve this problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "41ece182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n",
      "Best CV accuracy: 0.9770310024892511\n",
      "Training accuracy: 0.9851776420004525\n",
      "Best parameters: {'clf__C': 0.01768682900898522, 'pca__n_components': 200, 'select__k': 600}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.stats import loguniform\n",
    "import numpy as np\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"scale\", StandardScaler()),\n",
    "    (\"var_thresh\", VarianceThreshold(threshold=0.0)),\n",
    "    (\"select\", SelectKBest(score_func=f_classif)), \n",
    "    (\"pca\", PCA(random_state=42)),\n",
    "    (\"clf\", LogisticRegression(max_iter=1000, solver='liblinear', random_state=42))\n",
    "])\n",
    "\n",
    "param_distributions = {\n",
    "    \"select__k\": np.arange(100, 1001, 100),\n",
    "    \"pca__n_components\": np.arange(50, 201, 50),\n",
    "    \"clf__C\": loguniform(1e-3, 1e3),\n",
    "\n",
    "}\n",
    "\n",
    "search_lr = RandomizedSearchCV(\n",
    "    pipe,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=30,\n",
    "    cv=3,\n",
    "    random_state=42,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "search_lr.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best CV accuracy:\", search_lr.best_score_)\n",
    "print (\"Training accuracy:\", search_lr.score(X_train, y_train))\n",
    "print(\"Best parameters:\", search_lr.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d255215",
   "metadata": {},
   "source": [
    "Tuning improved our model: the training and CV accuracies are close, suggesting that are no overfitting. Our model is now better balanced for this classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "d0d41f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "Best CV accuracy: 0.9756732292373841\n",
      "Training accuracy: 0.9854039375424304\n",
      "Best parameters: {'clf__C': 0.015369603110608839, 'pca__n_components': 200, 'select__k': 600}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from scipy.stats import loguniform\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"scale\", StandardScaler()),\n",
    "    (\"var_thresh\", VarianceThreshold(threshold=0.0)),\n",
    "    (\"select\", SelectKBest(score_func=f_classif)), \n",
    "    (\"pca\", PCA(random_state=42)),\n",
    "    (\"clf\", SVC(kernel='linear', probability=False, random_state=42)) \n",
    "])\n",
    "\n",
    "param_distributions = {\n",
    "    \"select__k\": np.arange(200, 1001, 200),\n",
    "    \"pca__n_components\": np.arange(50, 201, 50),\n",
    "    \"clf__C\": loguniform(1e-2, 1e2),              \n",
    "}\n",
    "\n",
    "search_svm = RandomizedSearchCV(\n",
    "    pipe,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=20,\n",
    "    cv=3,\n",
    "    random_state=42,\n",
    "    verbose=1,\n",
    "    n_jobs=-1  \n",
    ")\n",
    "\n",
    "search_svm.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best CV accuracy:\", search_svm.best_score_)\n",
    "print(\"Training accuracy:\", search_svm.score(X_train, y_train))\n",
    "print(\"Best parameters:\", search_svm.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99840f18",
   "metadata": {},
   "source": [
    "The tuned SVM model achieved excellent CV accuracy and a small gap between training and CV accuracy. Both Logistic Regression and SVM now perform very well on our classification task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1646ab9",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65ab5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = ''\n",
    "\n",
    "with open(file_path, 'r') as f:\n",
    "    header = f.readline().replace('\"', '').strip().split()\n",
    "\n",
    "header = ['Gene'] + header\n",
    "\n",
    "df_test = pd.read_csv(file_path,\n",
    "                 sep='\\s+',        \n",
    "                 quotechar='\"',    \n",
    "                 skiprows=1,       \n",
    "                 header=None)      \n",
    "\n",
    "df_test.columns = header\n",
    "df_test.set_index('Gene', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e14b0544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 3671)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head(5)\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3f2fdb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test= df_test.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e519469d",
   "metadata": {},
   "source": [
    "### Loading our Best models for both classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333038b6",
   "metadata": {},
   "source": [
    "Our two best models are Logistic Regression and SVM. We will use them on the test set to make predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f2233e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: Pipeline(steps=[('scale', StandardScaler()),\n",
      "                ('var_thresh', VarianceThreshold()),\n",
      "                ('select', SelectKBest(k=600)),\n",
      "                ('pca', PCA(n_components=200, random_state=42)),\n",
      "                ('clf',\n",
      "                 LogisticRegression(C=0.01768682900898522, max_iter=1000,\n",
      "                                    random_state=42, solver='liblinear'))])\n"
     ]
    }
   ],
   "source": [
    "model_lr = search_lr.best_estimator_\n",
    "print(\"Best model:\", model_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "1fa5bee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: Pipeline(steps=[('scale', StandardScaler()),\n",
      "                ('var_thresh', VarianceThreshold()),\n",
      "                ('select', SelectKBest(k=600)),\n",
      "                ('pca', PCA(n_components=200, random_state=42)),\n",
      "                ('clf',\n",
      "                 SVC(C=0.015369603110608839, kernel='linear',\n",
      "                     random_state=42))])\n"
     ]
    }
   ],
   "source": [
    "model_svm = search_svm.best_estimator_\n",
    "print(\"Best model:\", model_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "52d27e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted labels: [0 0 0 1 1 1 1 0 0 1]\n",
      "Predicted labels shape: (3671,)\n"
     ]
    }
   ],
   "source": [
    "label_predict_lr = model_lr.predict(X_test)\n",
    "print(\"Predicted labels:\", label_predict_lr[:10])\n",
    "print(\"Predicted labels shape:\", label_predict_lr.shape)\n",
    "\n",
    "with open(\"predictions_HCC1806_DropSeq_lr.txt\", \"w\") as f:\n",
    "    for label in label_predict_lr:\n",
    "        f.write(f\"{label}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "1dc5829a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted labels: [0 0 0 1 1 1 1 0 0 1]\n",
      "Predicted labels shape: (3671,)\n"
     ]
    }
   ],
   "source": [
    "label_predict_svm= model_svm.predict(X_test)\n",
    "print(\"Predicted labels:\", label_predict_svm[:10])\n",
    "print(\"Predicted labels shape:\", label_predict_svm.shape)\n",
    "\n",
    "with open(\"predictions_HCC1806_DropSeq_svm.txt\", \"w\") as f:\n",
    "    for label in label_predict_svm:\n",
    "        f.write(f\"{label}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "858cbae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mismatches: 65\n"
     ]
    }
   ],
   "source": [
    "mask = label_predict_svm != label_predict_lr\n",
    "print(\"Number of mismatches:\", mask.sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486db5c1",
   "metadata": {},
   "source": [
    "Since there are very few mismatches between the predictions of our two models, both can be used to make predictions on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8225d9d",
   "metadata": {},
   "source": [
    "# Comparisons with MCF7 Cell Line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f3e022",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = ''\n",
    "\n",
    "with open(file_path, 'r') as f:\n",
    "    header = f.readline().replace('\"', '').strip().split()\n",
    "\n",
    "header = ['Gene'] + header\n",
    "\n",
    "Mc = pd.read_csv(file_path,\n",
    "                 sep='\\s+',        \n",
    "                 quotechar='\"',    \n",
    "                 skiprows=1,      \n",
    "                 header=None)     \n",
    "\n",
    "Mc.columns = header\n",
    "Mc.set_index('Gene', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2b51beda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 21626)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Mc.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad5630a",
   "metadata": {},
   "source": [
    "Cell Filtering Again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "21c9b921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    12705\n",
      "1     8921\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "sample_names_train =Mc.T.index\n",
    "\n",
    "labels_array=np.array([1 if \"Hypoxia\" in name else 0 for name in sample_names_train])\n",
    "print(pd.Series(labels_array, index=sample_names_train).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8804f250",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_series = pd.Series(labels_array, index=Mc.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "cd233a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "hypoxia_cells = labels_series[labels_series == 1].index\n",
    "normoxia_cells = labels_series[labels_series == 0].index\n",
    "\n",
    "expr_hypoxia = Mc[hypoxia_cells]\n",
    "expr_normoxia = Mc[normoxia_cells]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9229cec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_hypoxia = expr_hypoxia.loc[:, (expr_hypoxia != 0).sum(axis=0) >= 70]\n",
    "filtered_normoxia = expr_normoxia.loc[:, (expr_normoxia != 0).sum(axis=0) >= 80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4d268c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_Mc = pd.concat([filtered_hypoxia, filtered_normoxia], axis=1)\n",
    "filtered_labels = labels_series[filtered_df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f93789ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    4768\n",
      "0    4663\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(filtered_labels.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0305ae32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    4768\n",
      "0    4663\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "sample_names_train =filtered_Mc.T.index\n",
    "\n",
    "m_train = np.array([1 if \"Hypoxia\" in name else 0 for name in sample_names_train])\n",
    "\n",
    "print(pd.Series(m_train, index=sample_names_train).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "fef0e7d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9431, 3000)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M_train = filtered_Mc.T.copy()\n",
    "M_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8132a045",
   "metadata": {},
   "source": [
    "Keeping the same parameteres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f19e086f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.9932138691549146\n"
     ]
    }
   ],
   "source": [
    "model_MCF = model_svm.fit(M_train, m_train)\n",
    "print(\"Training accuracy:\", model_MCF.score(M_train, m_train))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8aad1c9",
   "metadata": {},
   "source": [
    "With this training accuracy the model can still fit MCF7.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "54ff16c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_genes = X_train.columns.intersection(M_train.columns)\n",
    "X_train_aligned = X_train[common_genes]\n",
    "M_train_aligned = M_train[common_genes]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "aa07e752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on MCF using HCC-trained model: 0.7296\n"
     ]
    }
   ],
   "source": [
    "model_svm.fit(X_train_aligned, y_train)\n",
    "acc = model_svm.score(M_train_aligned, m_train)\n",
    "print(f\"Accuracy on MCF using HCC-trained model: {acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ea0e40",
   "metadata": {},
   "source": [
    "This tells that the decision boundary and variance structure learned on HCC1806 cells do not generalize to MCF7 cells. Hypoxia signatures in one cell line aren’t the same in the other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe2faa0",
   "metadata": {},
   "source": [
    "# Comparing with smartseq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198257aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Hcc = pd.read_csv(\"\",delim_whitespace=True, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "23f15c12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 182)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Hcc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40885a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Hcc = Hcc.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b724f910",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_genes = X_train.columns.intersection(Hcc.columns)\n",
    "X_train_aligned = X_train[common_genes]\n",
    "Hcc_aligned = Hcc[common_genes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "56690901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    3000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "sample_train = Hcc.index\n",
    "\n",
    "hcc_train = np.array([1 if \"Hypo\" in name else 0 for name in sample_train])\n",
    "\n",
    "print(pd.Series(hcc_train, index=sample_train).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1a4536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8838, 0)\n",
      "(3000, 0)\n",
      "182\n",
      "3000\n"
     ]
    }
   ],
   "source": [
    "print(X_train_aligned.shape)   \n",
    "print(Hcc_aligned.shape)       \n",
    "print(len(y_train))            \n",
    "print(len(hcc_train))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41eaead8",
   "metadata": {},
   "source": [
    "It is possible that they have no common features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da8da12",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_svm.fit(X_train_aligned, y_train)\n",
    "acc = model_svm.score(Hcc_aligned, Hcc)\n",
    "print(f\"Accuracy on MCF using HCC-trained model: {acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
